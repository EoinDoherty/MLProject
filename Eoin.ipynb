{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Year</th>\n",
       "      <th>AdjustedRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Thriller', 'Science Fiction', 'Horror', 'Adv...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.022468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['Thriller', 'Erotic thriller', 'Psychological...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983</td>\n",
       "      <td>['German Language']</td>\n",
       "      <td>['Germany']</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18998739</td>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['South Africa']</td>\n",
       "      <td>['Family Film', 'Fantasy', 'Adventure', 'World...</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Little city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Romantic comedy', 'Ensemble Film', 'Comedy-d...</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WikiID                       Name     Revenue ReleaseDate  \\\n",
       "0    975900             Ghosts of Mars  14010832.0  2001-08-24   \n",
       "1   9363483           White Of The Eye         NaN        1987   \n",
       "2    261236          A Woman in Flames         NaN        1983   \n",
       "3  18998739  The Sorcerer's Apprentice         NaN        2002   \n",
       "4   6631279                Little city         NaN  1997-04-04   \n",
       "\n",
       "              Languages                     Countries  \\\n",
       "0  ['English Language']  ['United States of America']   \n",
       "1  ['English Language']            ['United Kingdom']   \n",
       "2   ['German Language']                   ['Germany']   \n",
       "3  ['English Language']              ['South Africa']   \n",
       "4  ['English Language']  ['United States of America']   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  ['Thriller', 'Science Fiction', 'Horror', 'Adv...   \n",
       "1  ['Thriller', 'Erotic thriller', 'Psychological...   \n",
       "2                                          ['Drama']   \n",
       "3  ['Family Film', 'Fantasy', 'Adventure', 'World...   \n",
       "4  ['Romantic comedy', 'Ensemble Film', 'Comedy-d...   \n",
       "\n",
       "                                             Summary    Year  AdjustedRevenue  \n",
       "0  Set in the second half of the 22nd century, th...  2001.0     2.022468e+07  \n",
       "1  A series of murders of rich young women throug...  1987.0              NaN  \n",
       "2  Eva, an upper class housewife, becomes frustra...  1983.0              NaN  \n",
       "3  Every hundred years, the evil Morgana  returns...  2002.0              NaN  \n",
       "4  Adam, a San Francisco-based artist who works a...  1997.0              NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCMU = pd.read_csv(\"ExportedData/cleanCMURevenueAdjusted.tsv\", sep=\"\\t\")\n",
    "dfCMU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCMU[\"Languages\"] = dfCMU.apply(lambda row: eval(row[\"Languages\"]), axis=1)\n",
    "dfCMU[\"Countries\"] = dfCMU.apply(lambda row: eval(row[\"Countries\"]), axis=1)\n",
    "dfCMU[\"Genres\"] = dfCMU.apply(lambda row: eval(row[\"Genres\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dfCMU.dropna(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "titleVectorizer = CountVectorizer()\n",
    "titleX = titleVectorizer.fit_transform(train[\"Name\"])\n",
    "dfCMU[\"tokenizedTitle\"] = titleX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dfCMU.dropna(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleX.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train[[\"tokenizedTitle\", \"Revenue\", \"Languages\", \"Countries\", \"Genres\", \"Summary\", \"AdjustedRevenue\"]]\n",
    "label = train[\"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GaussianNB()\n",
    "# gb.fit(features[\"AdjustedRevenue\"].values.reshape(-1,1), label.values)\n",
    "# predictions = gb.predict(test[\"AdjustedRevenue\"].values.reshape(-1,1))\n",
    "gb.fit(titleX.toarray(), label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTitles = titleVectorizer.transform(test[\"Name\"]).toarray()\n",
    "predictions = gb.predict(testTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019256308100929615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions == test[\"Year\"])/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(titleX.toarray(), label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn.predict(testTitles[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.62"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predict - test[\"Year\"][:100])/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCMU[\"Decade\"] = 10 * np.round(dfCMU[\"Year\"]/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Year</th>\n",
       "      <th>AdjustedRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Thriller', 'Science Fiction', 'Horror', 'Adv...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.022468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['Thriller', 'Erotic thriller', 'Psychological...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983</td>\n",
       "      <td>['German Language']</td>\n",
       "      <td>['Germany']</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18998739</td>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['South Africa']</td>\n",
       "      <td>['Family Film', 'Fantasy', 'Adventure', 'World...</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Little city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Romantic comedy', 'Ensemble Film', 'Comedy-d...</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WikiID                       Name     Revenue ReleaseDate  \\\n",
       "0    975900             Ghosts of Mars  14010832.0  2001-08-24   \n",
       "1   9363483           White Of The Eye         NaN        1987   \n",
       "2    261236          A Woman in Flames         NaN        1983   \n",
       "3  18998739  The Sorcerer's Apprentice         NaN        2002   \n",
       "4   6631279                Little city         NaN  1997-04-04   \n",
       "\n",
       "              Languages                     Countries  \\\n",
       "0  ['English Language']  ['United States of America']   \n",
       "1  ['English Language']            ['United Kingdom']   \n",
       "2   ['German Language']                   ['Germany']   \n",
       "3  ['English Language']              ['South Africa']   \n",
       "4  ['English Language']  ['United States of America']   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  ['Thriller', 'Science Fiction', 'Horror', 'Adv...   \n",
       "1  ['Thriller', 'Erotic thriller', 'Psychological...   \n",
       "2                                          ['Drama']   \n",
       "3  ['Family Film', 'Fantasy', 'Adventure', 'World...   \n",
       "4  ['Romantic comedy', 'Ensemble Film', 'Comedy-d...   \n",
       "\n",
       "                                             Summary    Year  AdjustedRevenue  \n",
       "0  Set in the second half of the 22nd century, th...  2001.0     2.022468e+07  \n",
       "1  A series of murders of rich young women throug...  1987.0              NaN  \n",
       "2  Eva, an upper class housewife, becomes frustra...  1983.0              NaN  \n",
       "3  Every hundred years, the evil Morgana  returns...  2002.0              NaN  \n",
       "4  Adam, a San Francisco-based artist who works a...  1997.0              NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCMU = pd.read_csv(\"ExportedData/cleanCMURevenueAdjusted.tsv\", sep=\"\\t\")\n",
    "dfCMU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCMU[\"Decade\"] = 10 * np.round(dfCMU[\"Year\"]/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(dfCMU, test_size=0.2)\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Year</th>\n",
       "      <th>AdjustedRevenue</th>\n",
       "      <th>Decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18271</th>\n",
       "      <td>25081461</td>\n",
       "      <td>Defenseless</td>\n",
       "      <td>6413375.0</td>\n",
       "      <td>1991-08-23</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Thriller', 'Crime Fiction', 'Mystery', 'Dram...</td>\n",
       "      <td>Lawyer T.K. represents Steven Seldes who claim...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1.202655e+07</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10346</th>\n",
       "      <td>835057</td>\n",
       "      <td>The In-Laws</td>\n",
       "      <td>38200000.0</td>\n",
       "      <td>1979-06-15</td>\n",
       "      <td>['English Language', 'Spanish Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Crime Fiction', 'Comedy']</td>\n",
       "      <td>The daughter of mild-mannered Manhattan dentis...</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1.346221e+08</td>\n",
       "      <td>1980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30835</th>\n",
       "      <td>22092460</td>\n",
       "      <td>Universal Soldiers: Regeneration</td>\n",
       "      <td>844447.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>['Russian Language', 'English Language', 'Bulg...</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Action/Adventure', 'Thriller', 'Science Fict...</td>\n",
       "      <td>A group of terrorists led by Commander Topov  ...</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.005856e+06</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41017</th>\n",
       "      <td>10780993</td>\n",
       "      <td>Vicky Cristina Barcelona</td>\n",
       "      <td>96408652.0</td>\n",
       "      <td>2008-05-17</td>\n",
       "      <td>['English Language', 'Spanish Language']</td>\n",
       "      <td>['United States of America', 'Spain']</td>\n",
       "      <td>['Romantic drama', 'Romance Film', 'Drama']</td>\n",
       "      <td>{{Plot}} Vicky  and Cristina  visit Barcelona ...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.144363e+08</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14603</th>\n",
       "      <td>2381862</td>\n",
       "      <td>Night of the Comet</td>\n",
       "      <td>14418922.0</td>\n",
       "      <td>1984-11-16</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Action/Adventure', 'Science Fiction', 'Horro...</td>\n",
       "      <td>The Earth is going to pass through the tail of...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>3.550877e+07</td>\n",
       "      <td>1980.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WikiID                              Name     Revenue ReleaseDate  \\\n",
       "18271  25081461                       Defenseless   6413375.0  1991-08-23   \n",
       "10346    835057                       The In-Laws  38200000.0  1979-06-15   \n",
       "30835  22092460  Universal Soldiers: Regeneration    844447.0        2009   \n",
       "41017  10780993          Vicky Cristina Barcelona  96408652.0  2008-05-17   \n",
       "14603   2381862                Night of the Comet  14418922.0  1984-11-16   \n",
       "\n",
       "                                               Languages  \\\n",
       "18271                               ['English Language']   \n",
       "10346           ['English Language', 'Spanish Language']   \n",
       "30835  ['Russian Language', 'English Language', 'Bulg...   \n",
       "41017           ['English Language', 'Spanish Language']   \n",
       "14603                               ['English Language']   \n",
       "\n",
       "                                   Countries  \\\n",
       "18271           ['United States of America']   \n",
       "10346           ['United States of America']   \n",
       "30835           ['United States of America']   \n",
       "41017  ['United States of America', 'Spain']   \n",
       "14603           ['United States of America']   \n",
       "\n",
       "                                                  Genres  \\\n",
       "18271  ['Thriller', 'Crime Fiction', 'Mystery', 'Dram...   \n",
       "10346                        ['Crime Fiction', 'Comedy']   \n",
       "30835  ['Action/Adventure', 'Thriller', 'Science Fict...   \n",
       "41017        ['Romantic drama', 'Romance Film', 'Drama']   \n",
       "14603  ['Action/Adventure', 'Science Fiction', 'Horro...   \n",
       "\n",
       "                                                 Summary    Year  \\\n",
       "18271  Lawyer T.K. represents Steven Seldes who claim...  1991.0   \n",
       "10346  The daughter of mild-mannered Manhattan dentis...  1979.0   \n",
       "30835  A group of terrorists led by Commander Topov  ...  2009.0   \n",
       "41017  {{Plot}} Vicky  and Cristina  visit Barcelona ...  2008.0   \n",
       "14603  The Earth is going to pass through the tail of...  1984.0   \n",
       "\n",
       "       AdjustedRevenue  Decade  \n",
       "18271     1.202655e+07  1990.0  \n",
       "10346     1.346221e+08  1980.0  \n",
       "30835     1.005856e+06  2010.0  \n",
       "41017     1.144363e+08  2010.0  \n",
       "14603     3.550877e+07  1980.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y = train[\"Decade\"]\n",
    "# train_X = train.drop([\"Decade\", \"Year\", \"ReleaseDate\"], axis=1)\n",
    "train_X = train[[\"Name\", \"Revenue\", \"Languages\", \"Countries\", \"Genres\", \"Summary\", \"AdjustedRevenue\"]]\n",
    "\n",
    "test_y = test[\"Decade\"]\n",
    "# train_X = train.drop([\"Decade\", \"Year\", \"ReleaseDate\"], axis=1)\n",
    "test_X = test[[\"Name\", \"Revenue\", \"Languages\", \"Countries\", \"Genres\", \"Summary\", \"AdjustedRevenue\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decade from title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "titleTokenizer = CountVectorizer()\n",
    "trainTitle = titleTokenizer.fit_transform(train_X[\"Name\"])\n",
    "testTitle = titleTokenizer.transform(test_X[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GaussianNB()\n",
    "gb.fit(trainTitle.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gb.predict(testTitle.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14491758241758243"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions == test_y)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(trainTitle.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn.predict(testTitle.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21648793565683647"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predict == test_y)/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5426"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainTitle.toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decade from plot summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTokenizer = CountVectorizer()\n",
    "trainPlots = plotTokenizer.fit_transform(train_X[\"Summary\"])\n",
    "testPlots = plotTokenizer.transform(test_X[\"Summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GaussianNB()\n",
    "gb.fit(trainPlots.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3173076923076923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = gb.predict(testPlots.toarray())\n",
    "sum(predict == test_y)/len(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(trainPlots.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn.predict(testPlots.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23927613941018766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predict == test_y)/len(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict based off of title and plot summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCombo = np.concatenate((trainPlots.toarray(), trainTitle.toarray()), axis=1)\n",
    "testCombo = np.concatenate((testPlots.toarray(), testTitle.toarray()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GaussianNB()\n",
    "gb.fit(trainCombo, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3240556660039761"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = gb.predict(testCombo)\n",
    "sum(predict == test_y)/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e8ae0695e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainCombo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(trainCombo[:10], train_y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Set in the second half of the 22nd century, the film depicts Mars as a planet that has been 84% terraformed, allowing humans to walk on the surface without wearing pressure suits. The Martian society has become largely matriarchal, with women in most positions of authority. The story concerns a police officer, Melanie Ballard , second in command of a small team alongside Sergeant Jericho  sent to pick up and transport a prisoner named Desolation Williams . Arriving at the remote mining town where Williams is being held, Ballard finds virtually all of the people missing. She learns that the miners had discovered an underground doorway created by an ancient Martian civilization. When the door was opened it released \"ghosts,\" disembodied spirits which possessed the miners. Violence ensues, as the possessed miners commit horrific acts of death and destruction, as well as self-mutilation. With their team leader Helena Bradock  murdered, Ballard must fight off the attacking miners, escape the town, and destroy the ghosts, if possible. Unfortunately, her intentions are complicated by the fact that killing a possessed human merely releases the Martian spirit to possess another human. The team eventually decides to blow up a nuclear reactor to try and vaporize all of the ghosts. At several points in the film Sergeant Jericho shows a romantic interest in Ballard, mostly unreciprocated. Ballard\\'s crew along with survivors who manage to gather in the jail are eventually wiped out by the miners after many fierce battles and events , leaving only her and Williams after Sergeant Jericho and the other remaining officers and the two operators of the train are killed upon returning from a brief retreat to finish the fight. Not wanting the authorities to blame the massacre on him, he handcuffs Ballard to her cot and escapes from the train, leaving her to return home and deliver her report, which is received with skepticism by her superiors. While Ballard recuperates at a hospital, the released spirits, who weren\\'t destroyed after all, attack the city. The end scene sets the movie up for a sequel as Williams returns to team up with Ballard to fight the possessed.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCMU[\"Summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "plotVectorizer = TfidfVectorizer(max_features=200, stop_words=stopwords.words('english'))\n",
    "XObject = plotVectorizer.fit_transform(dfCMU[\"Summary\"])\n",
    "plotX = XObject.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agrees',\n",
       " 'along',\n",
       " 'also',\n",
       " 'another',\n",
       " 'apartment',\n",
       " 'appears',\n",
       " 'around',\n",
       " 'arrives',\n",
       " 'asks',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attempts',\n",
       " 'away',\n",
       " 'back',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'begins',\n",
       " 'behind',\n",
       " 'body',\n",
       " 'boy',\n",
       " 'brother',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'car',\n",
       " 'child',\n",
       " 'children',\n",
       " 'city',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'decides',\n",
       " 'despite',\n",
       " 'discovers',\n",
       " 'dr',\n",
       " 'end',\n",
       " 'ends',\n",
       " 'escape',\n",
       " 'even',\n",
       " 'eventually',\n",
       " 'face',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'father',\n",
       " 'fight',\n",
       " 'film',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'first',\n",
       " 'former',\n",
       " 'found',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'gang',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'good',\n",
       " 'group',\n",
       " 'gun',\n",
       " 'hand',\n",
       " 'head',\n",
       " 'help',\n",
       " 'high',\n",
       " 'home',\n",
       " 'hospital',\n",
       " 'house',\n",
       " 'however',\n",
       " 'husband',\n",
       " 'instead',\n",
       " 'jack',\n",
       " 'job',\n",
       " 'john',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'kills',\n",
       " 'king',\n",
       " 'know',\n",
       " 'last',\n",
       " 'later',\n",
       " 'learns',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'life',\n",
       " 'like',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'local',\n",
       " 'long',\n",
       " 'love',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'man',\n",
       " 'manages',\n",
       " 'many',\n",
       " 'marriage',\n",
       " 'married',\n",
       " 'marry',\n",
       " 'meanwhile',\n",
       " 'meet',\n",
       " 'meets',\n",
       " 'men',\n",
       " 'money',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'murder',\n",
       " 'must',\n",
       " 'name',\n",
       " 'named',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'old',\n",
       " 'one',\n",
       " 'order',\n",
       " 'parents',\n",
       " 'party',\n",
       " 'people',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'police',\n",
       " 'real',\n",
       " 'realizes',\n",
       " 'refuses',\n",
       " 'relationship',\n",
       " 'return',\n",
       " 'returns',\n",
       " 'reveals',\n",
       " 'room',\n",
       " 'run',\n",
       " 'runs',\n",
       " 'says',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'see',\n",
       " 'sees',\n",
       " 'set',\n",
       " 'several',\n",
       " 'shot',\n",
       " 'show',\n",
       " 'shows',\n",
       " 'since',\n",
       " 'sister',\n",
       " 'small',\n",
       " 'son',\n",
       " 'soon',\n",
       " 'starts',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'takes',\n",
       " 'team',\n",
       " 'tells',\n",
       " 'though',\n",
       " 'three',\n",
       " 'time',\n",
       " 'together',\n",
       " 'tom',\n",
       " 'town',\n",
       " 'train',\n",
       " 'tries',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turns',\n",
       " 'two',\n",
       " 'upon',\n",
       " 'using',\n",
       " 'village',\n",
       " 'wants',\n",
       " 'war',\n",
       " 'way',\n",
       " 'well',\n",
       " 'wife',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'work',\n",
       " 'world',\n",
       " 'would',\n",
       " 'year',\n",
       " 'years',\n",
       " 'young']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoNan = dfCMU.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dfNoNan[\"Name\"]\n",
    "revenue = dfNoNan[\"AdjustedRevenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7530"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7530"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11954.587155963303"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dfCMU[\"AdjustedRevenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(dfCMU[\"Decade\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.column_stack((plotX, y))\n",
    "train_X, test_x, train_y, test_y = train_test_split(plotX, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-0dbd4110bac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_X, train_y)\n",
    "prediction = nb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
