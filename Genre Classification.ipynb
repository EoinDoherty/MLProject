{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pts = 30000\n",
    "mdat = pd.read_csv('cleanCMURevenueAdjusted.tsv', delimiter='\\t',encoding='utf-8-sig')\n",
    "plotsum = mdat[mdat.columns[7]]\n",
    "mdat[\"Genres\"] = mdat.apply(lambda row: eval(row[\"Genres\"]), axis=1)\n",
    "#g3 = mdat[\"Genres\"]\n",
    "gen = mdat[\"Genres\"]\n",
    "titles = mdat[\"Name\"]\n",
    "mdat.head()\n",
    "\n",
    "#Split\n",
    "Train2, Test2 = train_test_split(mdat, test_size=0.3)\n",
    "#Get plot data\n",
    "TrainPlot = Train2[mdat.columns[7]]\n",
    "TestPlot = Test2[mdat.columns[7]]\n",
    "#Get genre data\n",
    "TrainGen = Train2[\"Genres\"]\n",
    "TestGen = Test2[\"Genres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tf-idf the training plots\n",
    "TrainVec = TfidfVectorizer(max_features = 3000, stop_words = stopwords.words('english'))\n",
    "TrainPlotsVec = TrainVec.fit_transform(TrainPlot)\n",
    "#fit the test plots to this tf-idf\n",
    "TestPlotsVec =  TrainVec.transform(TestPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the points with genre lists that include comedy\n",
    "comTest = np.zeros((len(TestGen),))\n",
    "for jj in range(len(TestGen)):\n",
    "    if any(x == 'Comedy' for x in TestGen.iloc[jj]):\n",
    "        comTest[jj] = 1\n",
    "        \n",
    "comTrain = np.zeros((len(TrainGen),))\n",
    "for jj in range(len(TrainGen)):\n",
    "    if any(x == 'Comedy' for x in TrainGen.iloc[jj]):\n",
    "        comTrain[jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the points with genre lists that include horror or thriller\n",
    "horTrain = np.zeros((len(TrainGen),))\n",
    "for jj in range(len(TrainGen)):\n",
    "    if any(x == 'Horror' or x == 'Thriller' for x in TrainGen.iloc[jj]):\n",
    "        horTrain[jj] = 1\n",
    "        \n",
    "horTest = np.zeros((len(TestGen),))\n",
    "for jj in range(len(TestGen)):\n",
    "    if any(x == 'Horror' or x == 'Thriller' for x in TestGen.iloc[jj]):\n",
    "        horTest[jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7681250987205812\n"
     ]
    }
   ],
   "source": [
    "#GBC classify comedy\n",
    "abc = GradientBoostingClassifier()#n_estimators = 5, learning_rate = 1.0, max_depth = 1, random_state = 0 )\n",
    "m = abc.fit(TrainPlotsVec , comTrain)\n",
    "score = m.score(TestPlotsVec, comTest)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472753119570368"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% of points that are not comedy\n",
    "1-sum(comTest)/len(comTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8367556468172485\n"
     ]
    }
   ],
   "source": [
    "#GBC classify horror\n",
    "abc = GradientBoostingClassifier()#n_estimators = 5, learning_rate = 1.0, max_depth = 1, random_state = 0 )\n",
    "m = abc.fit(TrainPlotsVec , horTrain)\n",
    "horscore = m.score(TestPlotsVec, horTest)\n",
    "print(horscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7820249565629442"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum(horTest)/len(horTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
